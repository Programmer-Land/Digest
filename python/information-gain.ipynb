{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085cada0-9785-49ec-bb2e-b5adb757e8a3",
   "metadata": {},
   "source": [
    "# Information Gain\n",
    "### While reading about decision trees in the fist chapter of <a href=\"http://ciml.info/\">A Course in Machine Learning</a> I wanted to understand exactly what is \"information gain\" and after reading <a href=\"https://en.wikipedia.org/wiki/Information_gain_in_decision_trees\">Wikipedia article</a> and <a href=\"https://towardsdatascience.com/decision-trees-for-classification-id3-algorithm-explained-89df76e72df1\">a Medium story</a> found the matter still unclear.\n",
    "### Fortunately Wikipedia referenced <a href=\"https://www.numpyninja.com/post/what-is-entropy-and-information-gain-how-are-they-used-to-construct-decision-trees\">this great article on Numpy Ninja</a> and now I understand IG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d51609-2335-42cc-aa82-18b050881fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the article's example\n",
    "\n",
    "data = [(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), \n",
    "        (1, 0), (1, 0), (1, 0), (1, 0),\n",
    "        (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n",
    "\n",
    "dlen = len(data)\n",
    "\n",
    "ysum = sum(y for _, y in data)\n",
    "print(ysum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3938e3-0e4e-4f2c-bbfe-889814a09611",
   "metadata": {},
   "source": [
    "### Data is a list of (x, y) where y is our target variable. It has 2 values - 1 and 0\n",
    "### Now let's calculate entropy. It is a negative sum of target value frequences multiplied by frequency logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159004ea-2037-49d8-9704-9b76ba940e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def entropy(oclist):\n",
    "    res = 0\n",
    "    total = sum(oclist)\n",
    "    \n",
    "    for o in oclist:\n",
    "        f = o/total\n",
    "        res -= (f*log(f, 2))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc7131-96ab-4729-97a9-f38bc39daad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_entropy = entropy([ysum, dlen - ysum]) \n",
    "print(parent_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d6ee4-d51f-4df5-8abb-e0460264a36f",
   "metadata": {},
   "source": [
    "### Let's split our data on x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf5d40-eb6a-40bb-a90f-794455807c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = [y for x, y in data if x==0]\n",
    "print(data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ebac0-45fd-4c59-a412-b8c6f98f9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [y for x, y in data if x==1]\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aedd5-ab86-4287-a386-1c17e9a56525",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysum0 = sum(data0)\n",
    "dlen0 = len(data0)\n",
    "child0_entropy = entropy([ysum0, dlen0 - ysum0])\n",
    "\n",
    "ysum1 = sum(data1)\n",
    "dlen1 = len(data1)\n",
    "child1_entropy = entropy([ysum1, dlen1 - ysum1])\n",
    "\n",
    "print('child0_entropy = {}'.format(child0_entropy))\n",
    "print('child1_entropy = {}'.format(child1_entropy))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b7c11-40d0-40aa-822c-078e5a281564",
   "metadata": {},
   "source": [
    "### Weighted average entropy of children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce628dbb-0ea5-4b0b-b375-8dfafb49352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wae = (dlen0/dlen) * child0_entropy + (dlen1/dlen) * child1_entropy \n",
    "print(wae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606397d9-d978-46ed-bd1d-874ef0c45281",
   "metadata": {},
   "source": [
    "### And at last: ***Information Gain***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b48bd-cd73-4a36-80ff-18f4fb979046",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = parent_entropy - wae\n",
    "print(ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c81b79-cf1b-4b6a-9fa0-c1ad9ecc3d75",
   "metadata": {},
   "source": [
    "# Full-fledged decision tree: \n",
    "## binary, greedy, using weighted average entropy of children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90be72-c5a7-4792-97c6-93de48922c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def next_split(df, y_name):\n",
    "    'Finds index and threshold to split a df for the max information gain on y index'\n",
    "\n",
    "    df_len = len(df.index)\n",
    "    wae = float('inf')\n",
    "    ename = None\n",
    "    ethreshold = None\n",
    "    edfl = None\n",
    "    edfr = None\n",
    "\n",
    "    x_names = (name for name, _ in df.iteritems() if name != y_name)    \n",
    "    for name in x_names:\n",
    "        vals = sorted(df[name].value_counts().index)\n",
    "        for vi in range(1, len(vals)):\n",
    "            dfl = df[df[name] < vals[vi]]\n",
    "            dfr = df.drop(dfl.index)\n",
    "            local_wae = (len(dfl.index) / df_len) * entropy(dfl[y_name].value_counts()) \\\n",
    "                      + (len(dfr.index) / df_len) * entropy(dfr[y_name].value_counts())\n",
    "            if wae > local_wae:\n",
    "                wae = local_wae\n",
    "                ename = name\n",
    "                ethreshold = vals[vi]\n",
    "                edfl = dfl.drop(columns = [name])\n",
    "                edfr = dfr.drop(columns = [name])\n",
    "\n",
    "    if ename:\n",
    "        return (ename, ethreshold, edfl, edfr)\n",
    "        \n",
    "    return (None, None, None, None)    \n",
    "    \n",
    "class Leaf:\n",
    "    def __init__(self, val):\n",
    "        self.value = val\n",
    "        \n",
    "    def label(self, row):\n",
    "        return self.value\n",
    "        \n",
    "class Node(Leaf):\n",
    "    def __init__(self, name, threshold):\n",
    "        super().__init__(None)\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.l = None\n",
    "        self.r = None\n",
    "        \n",
    "    def label(self, row):\n",
    "        if row[self.name] < self.threshold:\n",
    "            return self.l.label(row)\n",
    "        else:\n",
    "            return self.r.label(row)\n",
    "\n",
    "def build_tree(df, y_name):\n",
    "    vc = df[y_name].value_counts()\n",
    "    if len(vc) > 1:\n",
    "        sname, sthreshold, sdfl, sdfr = next_split(df, y_name)\n",
    "        if (sname):\n",
    "            ret = Node(sname, sthreshold)\n",
    "            ret.l = build_tree(sdfl, y_name)\n",
    "            ret.r = build_tree(sdfr, y_name)\n",
    "            return ret\n",
    "    return Leaf(df[y_name].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac3d71-ad05-46fc-a7e8-f08a0b4b23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cervical Cancer Behavior Risk Data Set\n",
    "cc_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00537/sobar-72.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b965f2-81e0-4b4b-af49-a7dd0f3ef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8823390d-fbee-4406-b4b7-2988a49c0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_name = 'ca_cervix'\n",
    "\n",
    "# split to train and test using groupby in order to have roughly the same y-entropy in original, train and test sets\n",
    "df_train = cc_data.groupby(y_name).sample(frac=0.7, random_state = 9)\n",
    "df_test = cc_data.drop(df_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b2fea-f513-40d6-a5b5-2e7541a31d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(cc_data[y_name].value_counts()), entropy(df_train[y_name].value_counts()), entropy(df_test[y_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19988af-12cf-46b2-927d-b1352b238fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_tree(df_train, y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373132d-18ce-4cee-bf65-34bbb4022bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_t = 0\n",
    "n_f = 0\n",
    "\n",
    "for _, row in df_test.iterrows():    \n",
    "    res = root.label(row)\n",
    "    if res == row[y_name]:\n",
    "        n_t += 1\n",
    "    else:\n",
    "        n_f += 1\n",
    "\n",
    "print('{} samples labeled correctly, {} samples labeled wrongly, accuracy = {}'.format(n_t, n_f, n_t/(n_t + n_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff396b4-c5eb-435a-a9ba-5927a0199604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
